{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e976ea-ff76-4478-9717-eb589d389b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_data(df):\n",
    "    # Standardize column names\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5eb784-4dc0-4b02-843d-11ffc93e1291",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Handling missing values\n",
    "    df = df.ffill().bfill() # Forward & backward fill   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c250396-3ab9-4f90-aff0-6ee3d3f33a29",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Handling outliers (replace values beyond 1.5*IQR with median)\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        median = df[col].median()\n",
    "        df[col] = np.where((df[col] < lower_bound) | (df[col] > upper_bound), median, df[col])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b42b298-70cf-48fe-8ba1-43a4cc7b2381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load dataset (modify path accordingly)\n",
    "    df = pd.read_csv(r\"C:\\Users\\tejas\\OneDrive\\Desktop\\dataset\\creditcard.csv.zip\")\n",
    "    \n",
    "    # Clean the dataset\n",
    "    cleaned_df = clean_data(df)\n",
    "    \n",
    "    # Save cleaned data\n",
    "    cleaned_df.to_csv(r\"C:\\Users\\tejas\\OneDrive\\Desktop\\dataset\\creditcard.csv.zip\", index=False)\n",
    "    print(\"Data cleaning completed and saved as 'cleaned_dataset.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70121a61-ab79-4ecb-85e1-c9a0c0fed3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['class'])  # Features\n",
    "y = df['class']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e0ca1e-fe42-4e83-9019-402b7331396a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
